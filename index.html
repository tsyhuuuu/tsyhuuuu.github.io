<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="Tsy's Profile" />
        <meta name="author" content="Siyuan Tao" />
        <title>Tsy's Profile</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">TAO Siyuan</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpg" alt="プロフィール画像" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li> -->
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#achievements">Achievements</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        陶
                        <span class="text-primary">斯遠</span>
                    </h1>
                    <h2 class="mb-0">
                        <span class="text-primary">Siyuan</span>
                        TAO
                    </h2>
                    <div class="subheading mb-5">
                        Graduate School of Engineering, Department of Mechanical Engineering, The Univ. of Osaka. <br>
                        MAIL: <a href="suen.tou@eom.mech.eng.osaka-u.ac.jp">suen.tou@eom.mech.eng.osaka-u.ac.jp</a>
                    </div>
                    <p class="lead mb-5">I am a M2 student affiliated with the Ishikawa-Minami Laboratory, where I am conducting research on embodied learning algorithm and the quantization of Visual SLAM. My current research interests lie in Musculoskeletal Robotics and World Models. I have actively participated in various projects and competitions, where I gained hands-on experience in robot design and development. During my undergraduate years, I was a member of Robohan, contributing to a variety of robot-building initiatives. Outside of my academic and research pursuits, I enjoy playing tennis and watching anime. </p>
                    <div class="social-icons">
                        <!-- <a class="social-icon" href="#!"><i class="fab fa-linkedin-in"></i></a> -->
                        <a class="social-icon" href="https://github.com/tsyhuuuu"><i class="fab fa-github"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <!-- <section class="resume-section" id="experience">
                <div class="resume-section-content">
                    <h2 class="mb-5">Experience</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Student</h3>
                            <div class="subheading mb-3">Intelitec Solutions</div>
                            <p>Bring to the table win-win survival strategies to ensure proactive domination. At the end of the day, going forward, a new normal that has evolved from generation X is on the runway heading towards a streamlined cloud solution. User generated content in real-time will have multiple touchpoints for offshoring.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2013 - Present</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Web Developer</h3>
                            <div class="subheading mb-3">Intelitec Solutions</div>
                            <p>Capitalize on low hanging fruit to identify a ballpark value added activity to beta test. Override the digital divide with additional clickthroughs from DevOps. Nanotechnology immersion along the information highway will close the loop on focusing solely on the bottom line.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">December 2011 - March 2013</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Junior Web Designer</h3>
                            <div class="subheading mb-3">Shout! Media Productions</div>
                            <p>Podcasting operational change management inside of workflows to establish a framework. Taking seamless key performance indicators offline to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">July 2010 - December 2011</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Web Design Intern</h3>
                            <div class="subheading mb-3">Shout! Media Productions</div>
                            <p>Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base benefits. Dramatically visualize customer directed convergence without revolutionary ROI.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2008 - June 2010</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" /> -->
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">the University of Osaka</h3>
                            <div class="subheading mb-3">Bachelor of Mechanical Engineering</div>
                            <p>GPA: 3.61 / 4.00</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2019 - May 2024</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">the University of Osaka</h3>
                            <div class="subheading mb-3">Master of Mechanical Engineering (M1)</div>
                            <p>GPA: 3.71 / 4.00</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2024 - May 2026</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="subheading mb-3">Programming Languages & Tools</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item"><i class="fab fa-python"></i></li>
                        <li class="list-inline-item"><i class="fab fa-unity"></i></li>
                        <li class="list-inline-item"><i class="fab fa-ubuntu"></i></li>
                        <li class="list-inline-item"><i class="fab fa-raspberry-pi"></i></li>
                    </ul>
                    <div class="subheading mb-3">Other Skills</div>
                    <p> 1. Robotic control using ROS2 </p>
                    <p> 2. Automation Workflow Creation using Make </p>
                    <p> 3. Chinese, Japanese, English </p>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="interests">
                <div class="resume-section-content">
                    <h2 class="mb-5">Interests</h2>
                    <p>Apart from my research, I love staying active outdoors, especially playing tennis with friends. When indoors, I enjoy a variety of genres, including sci-fi, biographies, and anime, with Haikyuu!! being my all-time favorite. Additionally, I stay engaged with the latest advancements in biography, embodied AI and autonomous drone technology. I also enjoy creating automation tools to enhance my work efficiency. </p>
                </div>
            </section>
            <hr class="m-0" />
            <!-- achievements-->
            <section class="resume-section" id="achievements">
                <div class="resume-section-content">
                    <h2 class="mb-5">Achievements</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"></span>
                            1. (2021) Awarded the Special Prize at the NHK Student Robot Contest 2021.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            2. (2022) Won a bronze medal in a Kaggle competition: "Google AI4Code - Understand Code in Python Notebooks".
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            3. (2023) Achieved a TOEFL iBT score of 99 and a TOEIC Reading&Listening score of 860.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            4. (2024) Presented at the international AROB conference in the title of "Assessing the Impact of Dynamic Image Quantization based on Error Diffusion on Visual SLAM".
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            4. (2024) Received the Hatakeyama Award from the Japan Society of Mechanical Engineers.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            5. (2024) Passed the G-TEST 2024#3 certification.

                        </li>
                        <li>
                            <span class="fa-li"></span>
                            6. (2024) Presented a poster titled "Memory-Saving Factor Analysis of Visual-Inertial SLAM with Quantized Images" at the international SICE FES conference.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            7. (2024) Completed the Large Language Model Course 2024 organized by Matsuo-Iwasawa Lab in the University of Tokyo.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            8. (2025) The paper titled "Performance Evaluation of ORB-SLAM3 with Quantized Images" has been accepted for publication in the AROB Journal.
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            9. (2025) Completed the World Model Course 2024 organized by Matsuo-Iwasawa Lab in the University of Tokyo.
                        </li>
                    </ul>
                    <p> </p>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"></span>
                            1. (2021) NHK学生ロボコン2021にて特別賞を受賞
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            2. (2022) Kaggleコンペ「Google AI4Code - Understand Code in Python Notebooks」にて銅メダルを獲得
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            3. (2023) TOEFL iBTスコア99，TOEIC Reading&Listeningスコア860を取得
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            4. (2024) 国際会議AROBにてOS発表（発表テーマ：Assessing the Impact of Dynamic Image Quantization based on Error Diffusion on Visual SLAM）
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            4. (2024) 日本機械学会畠山賞を受賞
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            5. (2024) G検定2024#3に合格

                        </li>
                        <li>
                            <span class="fa-li"></span>
                            6. (2024) 国際会議SICE FESにてポスタ発表（発表テーマ：Memory-Saving Factor Analysis of Visual-Inertial SLAM with Quantized Images）
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            7. (2024) 東京大学松尾・岩澤研究室主催の「大規模言語モデル2024」講座を修了
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            8. (2025) 論文「Performance Evaluation of ORB-SLAM3 with Quantized Images」がAROB Journalにて採択
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            9. (2025) 東京大学松尾・岩澤研究室主催の「世界モデル2024」講座を修了
                        </li>
                    </ul>
                </div>
            </section>

            <!-- research-->
            <section class="resume-section" id="research">
                <div class="resume-section-content">
                    <h2 class="mb-5">Research</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"></span>
                            <b>1. [AROB2024・SICE FES2024・AROB Journal] Assessing the Impact of Dynamic Image Quantization based on Error Diffusion
                                on Visual SLAM / Memory-Saving Factor Analysis of Visual-Inertial SLAM with Quantized Images / Performance Evaluation of ORB-SLAM3 with Quantized Images</b>
                            <p>  </p>
                            <p>　Visual simultaneous localization and mapping(SLAM) is a critical technology for robots to perform high-precision navigation, increasing the focus among researchers to improve its accuracy. However, improvements in SLAM accuracy always come at the cost of an increased memory footprint, which limits the long-term operation of devices that operate under constrained hardwareresources. Application of quantization methods is proposed as a promising solution to this problem. Since quantization can result in performance degradation, itis crucial to quantitatively evaluate the trade-off between potential degradation and memory savings to assessits practicality for visual SLAM. This paper introducesa mechanism to evaluate the influence of a quantization method on visual SLAM, and applies it to assessthe impact of three different quantization methods on ORB-SLAM3. Specifically, we examine two static quantizationmethods and a dynamic quantization method called error diffusion, which can pseudo-preserve image shading information. The paper contributes to the conclusion that error diffusion, with controlled weight parameters in the error diffusion filter, can suppress degradation and reduce the memory footprint, demonstrating its effectiveness in dynamic environments. </p>
                            <br><img class="img-fluid img-profile mx-auto mb-2" src="assets/img/1_poster_sice.png" alt="SICE FESでのポスター" /><br>
                            <p>  </p>
                            Furthermore, as an extension beyond the conference presentation, we have validated the experiment in a real-time environment using Autoware and AWSIM (unity-based autonomous driving environment). The experimental setup is as follows.<br>
                            <p>  </p>
                            <!-- <video controls width="720" height="480">
                                <source src="assets/video/sice_extended1.mp4" type="video/mp4">
                            </video> -->
                            <br><img width="720" class="img-fluid img-profile mx-auto mb-2" src="assets/img/1_sice_extended1.png" alt="SICE FESでのポスター" /><br>
                            <p>  </p><br>
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            <b>2. [World Model2024] LLMによる身体化されたマルチエージェントシステムにおける知能のスケーリングと多様性の分析</b>
                            <p>  </p>
                            <p>　近年，World Model，Large Language Models（LLMs），およびVision-Language Models（VLMs）の発展に伴い，身体化されたAI エージェント（Embodied AI）の課題解決能力と連携能力が大幅に向上し，ロボティクスやゲーム分野において研究が盛んに行われている．その中で，Voyager[Wang 2023]をはじめとするMinecraft を舞台とした研究が代表例として挙げられる．Voyager では，LLM を活用した単体のエージェントが未知の環境において，与えられた課題に対して自律的に目標を計画し，環境を探索しながら新しいスキルを獲得することで，継続的な学習を通じて困難な課題を解決できることが示された．また，従来のマルチエージェントシステムにおける群知能も，課題解決において効果的であることが確認されている[Gronauer 2022]．そのため，マルチエージェントシステムにLLM を活用することで，更なる課題解決の効率向上が期待される．VillagerAgent[Dong 2024] やS-Agent[Chen 2024]では，LLM に由来する知能を持つエージェントによるエージェントシステムが，協調作業を通じてタスク効率を向上させることを示した．これに伴い，エージェントの組織構造設計やマルチモーダル技術の利用を中心に，タスク効率の向上を目的とした研究が行われてきた[Li 2024]．しかしながら，これらは大きなモデルサイズの高性能のLLM に基づく同質なエージェントによる実験に，異なる形式の知能がどのように相互作用し，どのように統合されるかについては，依然として十分に理解されていない．また, そのような大きなモデルサイズのLLM の利用は高いコストを必要とし, エージェントシステムの実用上の問題が生じることが考えられる.そこで本研究では，エージェントの知能や多様性が，マルチエージェントシステム内でのタスク効率に与える影響を分析する．具体的には，Minecraft をベースとしたシミュレータMineLand[Yu 2024] を用いて，AI エージェントの集団に建設や資源収集といった集団内の連携を要するタスクを課し，異なるモデルサイズのLLM やエージェントの内部状態を与えてそのパフォーマンスを評価する．この際，エージェントに異なる個性を付与するにあたり，Theory of Mind[Li 2023] やBig Five[Huang 2024] をLLM によるエージェントシステムに適用した研究をもとにシステムプロンプトを設計し，タスクの遂行や創発性への影響を検証する．なお，本研究は「世界モデル2024」講座の最終課題として実施され，その成果は東京大学山上会館にてポスター発表を行った．なお，本研究に用いたプログラムはhttps://github.com/Kosuke-K-21/embodied-world-model.gitで公開している．</p>
                            <br><img class="img-fluid img-profile mx-auto mb-2" src="assets/img/2_poster_wm.png" alt="世界モデルでのポスター" /><br>
                            <p>  </p><br>
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            <b>3. [Robomech2025] CLAHE ベース霧除去アルゴリズムによるドローン自律飛行の性能向上</b>
                            <p> ＊ ポスターの詳細はRobomech2025に参加後公開予定 ＊ </p>
                            <p>　地震や洪水，山火事などの災害現場では，迅速な被害状況の把握や捜索救助活動が求められる．その中で，ドローンは広範囲を効率的に監視し，危険区域への直接の人員投入を避ける手段として重要な役割を果たしている．しかし，災害現場ではしばしば濃霧や煙，粉じんなどが発生するため，カメラを用いた視覚ベースのドローン自律走行システムの性能を大きく低下させる要因となる．これにともない，ドローンの安全性や信頼性が損なわれ，十分な支援活動を行なうことが困難となる．
                            近年，霧や煙のある環境における画像復元技術は，主に事前知識に基づく手法と学習ベースの手法に分類される．事前知識に基づく手法には，大気散乱モデル（ASM: Atmospheric Scattering Model）などの物理的な事前知識を活用する手法や，CLAHE(Contrast Limited Adaptive Histogram Equalization) をはじめとしたヒストグラムを利用した手法が含まれる[1][2]．これらの画像復元手法は計算コストが低く，高速かつ安定した霧除去を実現できる．一方，学習ベースの手法では，深層学習モデルを用いて画像データから直接霧除去を行なう．とくに，最近の研究ではU-Net や拡散モデルを使用した手法が注目されており，これらによる高精度な霧除去が実現されている[3][4]．しかし，学習ベースの手法は計算コストが非常に高く，災害現場のようなリアルタイム処理が求められる環境では適用が困難である．同時に，計算資源を大量に消費するため，ドローンの稼働時間を大幅に減少するといった問題も存在する．さらに，上述の事前知識ベースの手法と学習ベースの手法はいずれも，SLAM(Simultaneous Localization and Mapping)システムとの統合において，定量的な評価が十分に行なわれていない．そのため，計算コストを抑えつつ高精度を維持するためのアプローチが必要が求められており，SLAM システムとの統合に向けた定量的な評価が必要となる．そこで本研究では，CLAHE を用いた低コストかつ高性能な画像復元技術を適用し，濃霧環境下でORB-SLAM3[5] を用いた自己位置推定性能に対する定量的な評価を行なう．評価において，現状公開されている霧ありデータセットには，画像間に時系列情報が欠如することから，SLAM の定量評価に適したデータセットが存在しない．そのため，本研究ではVisual SLAM 用のデータセットEuRoC Mav[6] におけるMH04 データセットをもとに，ASMを用いてさまざまな霧の強さを含むデータセットを生成する．そして，さまざまな濃霧環境下でORB-SLAM3 を用いた自己位置推定性能を定量的に検証することで，提案手法の有効性を明らかにする．</p>
                            <!-- <br><img class="img-fluid img-profile mx-auto mb-2" src="assets/img/3_poster_wm.png" alt="世界モデルでのポスター" /><br> -->
                            <p>  </p><br>
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            <b>4. [自主研究] 世界モデルによる筋骨格系ロボットの意識と行動パターンの調査</b>
                            <p> </p>
                            <p>　筋骨格系ロボットは，人間の運動機能を模倣し，高度な適応性と柔軟な動作を実現することができる．しかし，従来の制御手法では，環境変化への適応や長期的な行動計画に限界があり，より高度な認識・意思決定能力に乏しい．近年，世界モデルを活用したロボット制御が注目されており，ロボットが自身の環境を予測・理解し，それに基づいて最適な行動を選択するアプローチが研究されている．本研究では，世界モデルを活用した筋骨格系ロボットの意識と行動パターンの調査を目的とし，ロボットがどのように環境を認識し，適応的な運動戦略を形成するのかを調査する．特に，学習過程における自己意識の発現や，環境の不確実性に対する行動選択のメカニズムに着目し，シミュレーションおよび実機実験を通じて検証を行う．
                            現在はMujocoとGenesisにおける強化学習に用いる筋骨格モデルを作成している段階にあり，ここでは作成したMujoco環境での，簡略化した馬の筋骨格モデルを表す．
                            </p>
                            <br><img class="img-fluid img-profile mx-auto mb-2" src="assets/img/4_horse_model.png" alt="Mujoco horse model" /><br>
                            <p> </p><br>
                        </li>
                        <li>
                            <span class="fa-li"></span>
                            <b>5. [自主研究] Dreamer v2を用いたMsPacman環境での強化学習</b>
                            <p> </p>
                            <p>　モデルベース強化学習アルゴリズムDreamerV2を用いて Ms. Pacman環境での学習を行い，その性能と学習過程を評価する．DreamerV2は，エージェントが環境のダイナミクスを内部モデルとして学習し，実際の環境と対話することなく仮想的な試行錯誤を行うことで，効率的な学習を実現する手法である．Ms. Pacmanは報酬がスパースであるため，敵の動きを予測しながら長期的な行動計画を立てる必要があり，従来の強化学習アルゴリズムにとって学習が困難な課題の一つである．本研究は学習目的として取り組んでおり，DreamerV2の大規模化に伴い，精度が向上することを確認した．今後の展望として，DreamerV3やSTORMなどより高精度かつ安定な世界モデルで実験を行う．
                            </p>
                            <br><img class="img-fluid img-profile mx-auto mb-2" src="assets/img/5_mspacman_history.png" alt="Learning Plot of DreamerV2" /><br>
                        </li>
                    </ul>
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
